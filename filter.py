# -*- coding: utf-8 -*-
"""443.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kl8ZbzAZAcGtLrKS5G-ohzw_oE3OYrv0
"""
'''
from google.colab import drive
drive.mount('/content/drive')

!unzip /content/drive/MyDrive/ee443/final_project/data.zip -d /content/drive/MyDrive/ee443/final_project

!python /content/drive/MyDrive/ee443/final_project/detection/1_prepare_data_in_ultralytics_format.py

pip install ultralytics

!python /content/drive/MyDrive/ee443/final_project/detection/2_train_ultralytics.py

!python /content/drive/MyDrive/ee443/final_project/detection/3_inference_ultralytics.py

pip install torchreid

!python /content/drive/MyDrive/ee443/final_project/reid/1_extract_feature.py
'''
import numpy as np
import os

def load_txt(file_path):
    """Load data from a .txt file."""
    data = []
    with open(file_path, 'r') as f:
        for line in f:
            parts = line.strip().split(',')
            camera_id, tracking_id, frame_id = int(parts[0]), int(parts[1]), int(parts[2])
            x, y, width, height = float(parts[3]), float(parts[4]), float(parts[5]), float(parts[6])
            confidence_score = float(parts[7])

            data.append([camera_id, tracking_id, frame_id, x, y, width, height, confidence_score])
    return np.array(data)

def load_npy(file_path):
    """Load data from a .npy file."""
    return np.load(file_path,allow_pickle=True)

def filter_detections(txt_data, npy_data, threshold, ratio_threshold):
    """Filter detections based on confidence score and width-to-height ratio."""
    # Extract confidence scores from the txt data
    confidence_scores = txt_data[:, 7]

    # Calculate width-to-height ratios
    ratios = txt_data[:, 5] / txt_data[:, 6]

    # Filter based on confidence score and width-to-height ratio
    filtered_indices = np.where((confidence_scores >= threshold) & (ratios <= ratio_threshold))[0]

    # Filter txt_data and npy_data based on the indices
    filtered_txt_data = txt_data[filtered_indices]
    filtered_npy_data = npy_data[filtered_indices]

    return filtered_txt_data, filtered_npy_data

def save_txt(data, file_path):
    """Save data to a .txt file."""
    with open(file_path, 'w') as f:
        for row in data:
            # Convert the first three elements to integers, leave the rest as strings
            row_str = ",".join(map(str, row))  # Join elements of the row into a string, separating them with commas
            row_str = row_str.replace(".0,", ",")
            row_str += '\n'
            f.write(row_str)

CONFIDENCE_THRESHOLD = 0.3
RATIO_THRESHOLD = 2.5

detect = 'C:/Users/konya/Desktop/UW/ee classes/ee443/EE443_2024_Challenge/detection/runs/detect/inference/txt'
reid = 'C:/Users/konya/Desktop/UW/ee classes/ee443/EE443_2024_Challenge/runs/reid/inference'


data_list = {
    'val': ['camera_0005', 'camera_0017', 'camera_0025']
}

for folder in data_list['val']:
  print(folder)
  txt = os.path.join(detect, folder + '.txt')
  npy = os.path.join(reid, folder + '.npy')
  npy_data = load_npy(npy)
  txt_data = load_txt(txt)

  print('txt shape:' + str(txt_data.shape))
  print('npy shape:' + str(npy_data.shape))

  filtered_txt_data, filtered_npy_data = filter_detections(txt_data, npy_data, CONFIDENCE_THRESHOLD, RATIO_THRESHOLD)

  print('filtered txt shape:' + str(filtered_txt_data.shape))
  print('filtered npy shape:' + str(filtered_npy_data.shape))


  np.save(os.path.join(reid, folder + '_filtered.npy'), filtered_npy_data)
  save_txt(filtered_txt_data, os.path.join(detect, folder + '_filtered.txt'))